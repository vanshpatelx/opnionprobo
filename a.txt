endpoints
1. GET /events
2. GET /event/:ID
3. POST /user - creating user
4. GET /user
5. POST /order
6. POST /event
7. GET /categories
8. POST /categories


DB server : DB Pools, Consistent connection, BatchProcessing, Rollback try for 2 - 3 times

soln : To handle failed batch processing by sending the unsaved messages back to Server 1 for retry, we can use a Redis list (like a queue) to store failed batches. If a rollback occurs after multiple attempts, the failed messages are pushed to the Redis queue for Server 1 to pick up and resend.
we use caching from DB after each second so get accurate resuits, and handle lots of connections
caching logic : more accessed data, less accessed data like that in DB server, we call from here to get data
1. after event done, send to another table, eventtime fatch new table faster (1 sec), another table is (10 sec)
2. user register - add to cache directly, update - add cache, otherwise - every mins or 10 mins
3. order - each seconds for current events, events close - not need at - low freq cache 


problems
1. we must have to fetch user data each second because of balance conflict between both redis cache

// API Endpoints
1. All events - https://analytics.probo.in/api/v1/captureEvent
2. Socket.io Stock Price, Queue - wss://falcon.api.probo.in/socket.io/?EIO=4&transport=websocket
    1. auth token send
    2. Session ID,Subscribe orderbook and LTP
3. POST Place Order - https://prod.api.probo.in/api/v1/oms/order/initiate
4. Avaliable Quantity at that price - https://prod.api.probo.in/api/v3/tms/trade/bestAvailablePrice?eventId=3178203&requestType=availableQuantities
5. Crypto Tradingview - WSS - wss://widgetdata.tradingview.com/socket.io/websocket?from=widgetembed%2F&date=2024_10_18-11_18&page-uri=probo.in%2Fevents%2Fbitcoin-to-be-priced-at-6860600-usdt-or-more-at-1015-pm-ajema&ancestor-origin=probo.in



// TrackBook
[x] schema design for each on DB server with check
[ ] DB on Dockers
[ ] subscriber setup
[ ] handling bulk queries
[ ] handking RETRY queries - both side
[ ] Impment of basic routes
[ ] middleware setup
[ ] caching logic setup
[ ] check whole 2 servers work properly or not
[ ] build exchange in golang
[ ] WS server on golang again
[ ] again setup pubsubs




/*
Users
1. id
2. username
3. password
4. role


Events
1. id
2. name
3. endTime
4. description
5. sourceOfTruth

Categories
1. id
2. title
3. icon
4. description

Events_Categories_Mapping
1. id
2. categoryId
3. EventsId

Orders
1. id
2. eventId
3. side (yes or no)
4. type => buy or sell
5. qty
6. price
7. timestamp
8. filledQuantity
9. status ('Not Executed', 'Partial', 'Done')
10. userId

Trades
1. id
2. buyerId
3. sellerId
4. qty
5. price
6. eventId
7. timestamp

*/


portfolio schema
- eventId
- 

user related
- [X] register user
- [X] login user
- [x] addBalance
- [x] getBalance
- [ ] getPortfolio
- [x] admin get all users


order related
- [X] POST Order
- [X] get OrderBook
- [X] admin get all orderbooks
- [ ] admin get all trades


event related
- [x] get event
- [x] get all events
- [X] get categories
- [X] admin add categories
- [X] admin add events
- [X] admin maping categories with (directly change in table)


admin special related
- [ ] reset
- [ ] settlements


// Order status change
// add Trades


// design of API Endpoints
// after done events, settlemengts
// initial logic for caching and queues
// create table changes, DB changes Schemas
// subscribers changes
// test everything
// docker everything

// build exchange
// add redis, trade mechanism, and lots
// queue for exchange
// WS Server
// handling users in WS
// End to end setup
// docker